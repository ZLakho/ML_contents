Ques#1- What are the slope and y-intercept of the best fit line when you train a simple linear regression model?

The slope and y-intercept of the best-fit line when you train a simple linear regression model represent the relationship between the independent variable (X) and the dependent variable (Y).
Here in our code, values for slope and Y-intercept are:
Slope : 0.0013098492162501
Y-Intercept: 0.9297959452945

Ques#2- Report the R-squared and mean squared error values for each of the trained models.

A) FOR LINEAR REGRESSION

CODE:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

dataset = pd.read_csv("students.csv")
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 1].values

Q1 = np.percentile(y, 20)
Q3 = np.percentile(y, 60)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outlier_indices = np.where((y < lower_bound) | (y > upper_bound))
X_cleaned = np.delete(X, outlier_indices, axis=0)
y_cleaned = np.delete(y, outlier_indices)

X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.4, random_state=0)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

plt.scatter(X_train, y_train, color="red")
plt.plot(X_train, model.predict(X_train), color="yellow")
plt.show()

slope = model.coef_[0]
intercept = model.intercept_

print("Slope (Coefficient):", slope)
print("Y-Intercept:", intercept)

rsquare = model.score(X_train, y_train)
mse = mean_squared_error(y_test, y_pred)

print("R-squared for Linear Regression:", rsquare)
print("Mean Squared Error for Linear Regression:", mse)

ANSWER:

R-squared for Linear Regression: 0.42035157880031115
Mean Squared Error for Linear Regression: 0.03303954656870938

B) FOR POLYNOMIAL REGRESSION

CODE:

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score, mean_squared_error

dataset = pd.read_csv("students.csv")
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 1].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)

degree = 4  
poly = PolynomialFeatures(degree=degree)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

model = LinearRegression()
model.fit(X_train_poly, y_train)

y_pred = model.predict(X_test_poly)

X_train_sorted = X_train[:, 0]  
y_train_sorted = y_train  

sorted_indices = np.argsort(X_train_sorted)
X_train_sorted = X_train_sorted[sorted_indices]
y_train_sorted = y_train_sorted[sorted_indices]

plt.scatter(X_train_sorted, y_train_sorted, color="red")
plt.plot(X_train_sorted, model.predict(X_train_poly[sorted_indices]), color="yellow")
plt.show()

rsquare_poly = r2_score(y_test, y_pred)
mse_poly = mean_squared_error(y_test, y_pred)

print("R-squared for Polynomial Regression:", rsquare_poly)
print("Mean Squared Error for Polynomial Regression:", mse_poly)


ANSWER:

R-squared for Polynomial Regression: 0.4850847689841411
Mean Squared Error for Polynomial Regression: 0.035623759932367424

C) FOR DECIISION TREE REGRESSION

CODE:
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score, mean_squared_error

dataset = pd.read_csv("students.csv")
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 1].values

Q1 = np.percentile(y, 10)
Q3 = np.percentile(y, 40)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outlier_indices = np.where((y < lower_bound) | (y > upper_bound))
X_cleaned = np.delete(X, outlier_indices, axis=0)
y_cleaned = np.delete(y, outlier_indices)

X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.4, random_state=0)

model = DecisionTreeRegressor(random_state=60)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

rsquare = model.score(X_train, y_train)
print("R-squared on the training data:", rsquare)

plt.scatter(X_train, y_train, color="red")
X_train_sorted = np.sort(X_train, axis=0)
y_pred_sorted = model.predict(X_train_sorted)
plt.plot(X_train_sorted, y_pred_sorted, color="yellow")
plt.show()

rsquare_tree = r2_score(y_test, y_pred)
mse_tree = mean_squared_error(y_test, y_pred)

print("R-squared for Decision Tree Regression:", rsquare_tree)
print("Mean Squared Error for Decision Tree Regression:", mse_tree)

ANSWER:

R-squared for Decision Tree Regression: 0.9262377544703011
Mean Squared Error for Decision Tree Regression: 0.04549843749999999
